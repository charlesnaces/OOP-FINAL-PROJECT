{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_therule0 import JSONCleaner, JSONReader, AdvancedJSONReader\n",
    "import json\n",
    "\n",
    "# Use the sample data provided in the repository\n",
    "filepath = 'data/sample_data.json'\n",
    "print(f\"Loading data from: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae25e59",
   "metadata": {},
   "source": [
    "## Phase 1: Loading and Initial State\n",
    "\n",
    "The `JSONCleaner` automatically initializes a `JSONLoader` to load and validate the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the cleaner (loads data automatically)\n",
    "cleaner = JSONCleaner(filepath)\n",
    "print(f\"Cleaner object: {cleaner}\")\n",
    "print(f\"String representation: {str(cleaner)}\")\n",
    "\n",
    "# Access raw data via the new get_raw_data() method\n",
    "raw_data = cleaner.get_raw_data()\n",
    "print(f\"\\nRaw data (first 2 records):\")\n",
    "print(json.dumps(raw_data[:2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8ec86",
   "metadata": {},
   "source": [
    "## Phase 2: Data Cleaning with Method Chaining\n",
    "\n",
    "The `JSONCleaner` uses a **fluent interface** (method chaining) where each method returns `self`, allowing elegant pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain multiple cleaning operations\n",
    "cleaned_data = (\n",
    "    cleaner\n",
    "    .trim_whitespace()          # Remove leading/trailing whitespace\n",
    "    .remove_null_values()        # Remove null fields\n",
    "    .remove_duplicates()         # Keep only unique records\n",
    "    .get_cleaned_data()          # Extract the final result\n",
    ")\n",
    "\n",
    "print(f\"State after cleaning: {cleaner}\")\n",
    "print(f\"Cleaned data (first 2 records):\")\n",
    "print(json.dumps(cleaned_data[:2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62588bf8",
   "metadata": {},
   "source": [
    "## Phase 3: Reading and Analysis\n",
    "\n",
    "Pass cleaned data to `JSONReader` for read-only analysis with dunder methods demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reader for analysis\n",
    "reader = JSONReader(cleaned_data)\n",
    "print(f\"Reader repr: {repr(reader)}\")\n",
    "print(f\"Reader str: {str(reader)}\")\n",
    "print(f\"Length (using __len__): {len(reader)}\")\n",
    "\n",
    "# Get dataset shape\n",
    "rows, cols = reader.shape()\n",
    "print(f\"\\nDataset shape: {rows} rows × {cols} columns\")\n",
    "\n",
    "# List all columns\n",
    "columns = reader.get_columns()\n",
    "print(f\"Columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d74dcb",
   "metadata": {},
   "source": [
    "## Phase 4: Basic Analysis Methods\n",
    "\n",
    "The `JSONReader` provides built-in analysis methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "summary = reader.summary_stats()\n",
    "print(\"Summary Statistics:\")\n",
    "for col, stats in summary.items():\n",
    "    print(f\"  {col}: {stats}\")\n",
    "\n",
    "# Count missing values\n",
    "missing = reader.count_missing_values()\n",
    "print(f\"\\nMissing values per column: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be860210",
   "metadata": {},
   "source": [
    "## Phase 5: Advanced Analysis with Inheritance\n",
    "\n",
    "The `AdvancedJSONReader` subclass demonstrates **inheritance and polymorphism**, extending the base reader with specialized methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a615437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AdvancedJSONReader (subclass of JSONReader)\n",
    "advanced_reader = AdvancedJSONReader(cleaned_data)\n",
    "print(f\"Advanced reader: {advanced_reader}\")\n",
    "\n",
    "# Get dataset description\n",
    "description = advanced_reader.describe()\n",
    "print(f\"\\nDataset Description:\")\n",
    "for key, value in description.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cea799",
   "metadata": {},
   "source": [
    "## Phase 6: Advanced Methods\n",
    "\n",
    "Use specialized methods only available in the advanced reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b418a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values for a column (if it exists)\n",
    "if 'category' in advanced_reader.get_columns():\n",
    "    unique_categories = advanced_reader.get_unique_values('category')\n",
    "    print(f\"Unique categories: {unique_categories}\")\n",
    "\n",
    "# Filter by value\n",
    "if 'status' in advanced_reader.get_columns():\n",
    "    filtered = advanced_reader.filter_by_value('status', 'active')\n",
    "    print(f\"\\nFiltered reader (active records): {filtered}\")\n",
    "else:\n",
    "    print(\"No 'status' column found in sample data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9adea2",
   "metadata": {},
   "source": [
    "## Phase 7: Export to CSV\n",
    "\n",
    "Export cleaned data to CSV using the advanced reader's export functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_path = 'data/cleaned_output.csv'\n",
    "try:\n",
    "    advanced_reader.export_to_csv(output_path)\n",
    "    print(f\"✓ Successfully exported to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: CSV export skipped (sample data may not have suitable columns)\")\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d2616",
   "metadata": {},
   "source": [
    "## Summary: OOP Principles Demonstrated\n",
    "\n",
    "This notebook showcases key OOP concepts implemented in json_therule0:\n",
    "\n",
    "| Concept | Example |\n",
    "|---------|--------|\n",
    "| **Classes** | JSONLoader, JSONCleaner, JSONReader, AdvancedJSONReader |\n",
    "| **Encapsulation** | Private attributes (`__raw_data`, `__cleaned_data`); public accessors |\n",
    "| **Inheritance** | AdvancedJSONReader extends JSONReader |\n",
    "| **Polymorphism** | Subclass adds `export_to_csv()`, `filter_by_value()`, `describe()` |\n",
    "| **Composition** | JSONCleaner contains JSONLoader instance |\n",
    "| **Dunder Methods** | `__repr__()`, `__str__()`, `__eq__()`, `__len__()` |\n",
    "| **Method Chaining** | Fluent interface for intuitive data cleaning pipelines |\n",
    "\n",
    "## Installation & Usage\n",
    "\n",
    "To install and use json_therule0 in your projects:\n",
    "\n",
    "```bash\n",
    "pip install json-therule0\n",
    "```\n",
    "\n",
    "Then import and use:\n",
    "\n",
    "```python\n",
    "from json_therule0 import JSONCleaner, AdvancedJSONReader\n",
    "\n",
    "cleaner = JSONCleaner('data.json')\n",
    "cleaned = cleaner.trim_whitespace().remove_null_values().get_cleaned_data()\n",
    "reader = AdvancedJSONReader(cleaned)\n",
    "print(reader.describe())\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
